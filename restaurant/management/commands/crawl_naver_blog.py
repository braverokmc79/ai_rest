### ğŸ“ íŒŒì¼ êµ¬ì„± (Django ëª¨ë¸ê³¼ ì—°ë™ëœ í¬ë¡¤ëŸ¬) ###
# Jupyter í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ êµ¬ì„±

# âœ… 1. í™˜ê²½ì„¤ì •
import os
import django
import time
import random
import sys


# 1) __file__ â†’ commands
# 2) â†’ management
# 3) â†’ restaurant
# 4) â†’ ai_rest   â† ì—¬ê¸°ì— ì˜¬ë¼ì™€ì•¼ 'proj' ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
BASE_DIR = os.path.dirname(  # level 4
    os.path.dirname(         # level 3
        os.path.dirname(     # level 2
            os.path.dirname( # level 1
                os.path.abspath(__file__)
            )
        )
    )
)
sys.path.insert(0, BASE_DIR)


# settings ëª¨ë“ˆ ì§€ì • (í”„ë¡œì íŠ¸ í´ë”ëª…ì´ 'ai_rest'ë¼ë©´)
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "proj.settings")




django.setup()  # ì¥ê³  ì•± ì´ˆê¸°í™”

# âœ… 2. í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import re
import unicodedata
from restaurant.models import Article  # Django ëª¨ë¸ import

# âœ… 3. ì „ì²˜ë¦¬ í•¨ìˆ˜
def clean_text(text):
    text = "".join(c for c in text if not unicodedata.category(c).startswith("C"))
    text = re.sub(r"[ \t\n\r\f\v]+", " ", text)
    return text.strip()

# âœ… 4. ê°œë³„ ë¸”ë¡œê·¸ í˜ì´ì§€ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_naver_blog(url):
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('user-agent=Mozilla/5.0')

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    driver.get(url)

    try:
        iframe = driver.find_element(By.ID, "mainFrame")
        driver.switch_to.frame(iframe)
        driver.find_element(By.ID, "post-area")
        res = driver.page_source
    except Exception:
        res = driver.page_source  # iframe ì—†ëŠ” ê²½ìš°ë„ ëŒ€ë¹„

    driver.quit()

    soup = BeautifulSoup(res, "html.parser")
    content = soup.find("div", {"class": "se-main-container"}) or soup.find("div", {"id": "postViewArea"})
    if not content:
        return None, None

    # ì œëª© ì¶”ì¶œ
    title_tag = soup.find("h3") or soup.find("div", class_=re.compile("se-title|se_textarea"))
    title = clean_text(title_tag.text if title_tag else "ì œëª© ì—†ìŒ")

    # ë‚´ìš© ì¶”ì¶œ
    span_tag = content.find("span", text=re.compile("ë¸”ë¡œê·¸ê¸°ìë‹¨"))
    if span_tag:
        span_tag.decompose()
    content_text = clean_text(content.text)

    return title, content_text

# âœ… 5. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë¸”ë¡œê·¸ ë§í¬ ìˆ˜ì§‘ í›„ ì €ì¥
def crawl_naver_blogs(location="ê°•ë‚¨", keyword="ë§›ì§‘", max_count=10):
    chrome_options = Options()
    # chrome_options.add_argument('--headless')  # í™”ë©´ í™•ì¸ìš©ìœ¼ë¡œ ë„ê¸°
    chrome_options.add_argument('user-agent=Mozilla/5.0')

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)

    search_query = f"{location} {keyword} ë¦¬ë·°"
    url = f"https://search.naver.com/search.naver?where=view&sm=tab_hty.top&query={search_query}"
    driver.get(url)

    time.sleep(3)

    with open("naver_result.html", "w", encoding="utf-8") as f:
        f.write(driver.page_source)

    soup = BeautifulSoup(driver.page_source, "html.parser")

    blog_links = []
    for a_tag in soup.select("a.title_link"):  # ì—¬ê¸° ìˆ˜ì •
        link = a_tag.get("href")
        if link.startswith("https://blog.naver.com"):
            blog_links.append(link)

    ...

# âœ… 6. ì‹¤í–‰ ì˜ˆì‹œ
crawl_naver_blogs(location="ê°•ë‚¨", keyword="ë§›ì§‘", max_count=10)  # ê°œë°œ í…ŒìŠ¤íŠ¸ìš© 10ê°œë¶€í„°



# if __name__ == "__main__":
#     crawl_naver_blogs("ê°•ë‚¨", "ë§›ì§‘", max_count=100)